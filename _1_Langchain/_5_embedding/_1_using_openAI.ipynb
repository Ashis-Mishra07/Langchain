{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedding Techniques\n",
    "\n",
    "\n",
    "- converting texts into vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()   # to load all my env variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OpenAIEmbeddings(client=<openai.resources.embeddings.Embeddings object at 0x000002747ACF9570>, async_client=<openai.resources.embeddings.AsyncEmbeddings object at 0x000002747AEC83D0>, model='text_embedding-3-large', dimensions=None, deployment='text-embedding-ada-002', openai_api_version=None, openai_api_base=None, openai_api_type=None, openai_proxy=None, embedding_ctx_length=8191, openai_api_key=SecretStr('**********'), openai_organization=None, allowed_special=None, disallowed_special=None, chunk_size=1000, max_retries=2, request_timeout=None, headers=None, tiktoken_enabled=True, tiktoken_model_name=None, show_progress_bar=False, model_kwargs={}, skip_empty=False, default_headers=None, default_query=None, retry_min_seconds=4, retry_max_seconds=20, http_client=None, http_async_client=None, check_embedding_ctx_length=True)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "''' \n",
    "\n",
    "Types of Embeddings present\n",
    "\n",
    ">  text_embedding-3-large\n",
    ">  text_embedding-3-small\n",
    ">  text_embedding-ada-002\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "embeddings = OpenAIEmbeddings(model = \"text_embedding-3-large\")\n",
    "embeddings \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"This is tutorial on OPENAI embeddings\"\n",
    "query_result = embeddings.embed_query(text)   # This will convert it into vectors\n",
    "query_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to check the dimension of the query / vector so formed\n",
    "len(query_result)    # ex 3072"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to get custom dimension\n",
    "\n",
    "embeddings_1024 = OpenAIEmbeddings(model = \"text_embedding-3-large\", dimension = 512)\n",
    "query_result_1024 = embeddings_1024.embed_query(text)   # This will convert it into vectors\n",
    "len(query_result_1024)    # ex 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Now suppose we get the docs from the loader and then following steps will be performed .\n",
    "- Now recursive Splitting will be done and then convert into embeddings and then get store "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    \n",
    "    chunk_size=500,\n",
    "    chunk_overlap=50\n",
    ")\n",
    "\n",
    "final_documents = text_splitter.split_documents(docs)     # also option as create_documents\n",
    "final_documents "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vector Embedding and Vector StoreDB\n",
    "\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "db = Chroma.from_documents(final_documents, embeddings_1024)\n",
    "db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now how to query from this vector database \n",
    "\n",
    "query = \" dckcjcilrkjcrilck ehcrekcner richreklcnr reoicircrhope rcreniro cicj\"\n",
    "retrieved_result =  db.similarity_search(query)\n",
    "print(retrieved_result)  # this will give the whole output with has more similarity"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
